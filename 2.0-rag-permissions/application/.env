# The provider for the AI models to use.
MODEL_PROVIDER=openai

# The name of LLM model to use.
MODEL=gpt-4o-mini

# Name of the embedding model to use.
EMBEDDING_MODEL=text-embedding-3-large

# Dimension of the embedding model to use.
EMBEDDING_DIM=1024

# The questions to help users get started (multi-line).
# CONVERSATION_STARTERS=

# The OpenAI API key to use.
OPENAI_API_KEY=

# Temperature for sampling from the model.
# LLM_TEMPERATURE=

# Maximum number of tokens to generate.
# LLM_MAX_TOKENS=

# The number of similar embeddings to return when retrieving documents.
TOP_K=3

# Configuration for Pinecone vector store
PINECONE_API_KEY=

PINECONE_ENVIRONMENT=

PINECONE_INDEX_NAME=

PINECONE_DISABLE_RUNTIME_VALIDATIONS=true

# FILESERVER_URL_PREFIX is the URL prefix of the server storing the images generated by the interpreter.
FILESERVER_URL_PREFIX=http://localhost:3000/api/files

# Customize prompt to generate the next question suggestions based on the conversation history.
# Disable this prompt to disable the next question suggestions feature.
NEXT_QUESTION_PROMPT="You're a helpful assistant! Your task is to suggest the next question that user might ask.
Here is the conversation history
---------------------
{conversation}
---------------------
Given the conversation history, please give me 3 questions that you might ask next!
Your answer should be wrapped in three sticks which follows the following format:
```
<question 1>
<question 2>
<question 3>
```"

# The system prompt for the AI model.
SYSTEM_PROMPT=You are a helpful assistant who helps users with their questions.

# An additional system prompt to add citation when responding to user questions.
SYSTEM_CITATION_PROMPT='You have provided information from a knowledge base that has been passed to you in nodes of information.
Each node has useful metadata such as node ID, file name, page, etc.
Please add the citation to the data node for each sentence or paragraph that you reference in the provided information.
The citation format is: . [citation:<node_id>]()
Where the <node_id> is the unique identifier of the data node.

Example:
We have two nodes:
  node_id: xyz
  file_name: llama.pdf

  node_id: abc
  file_name: animal.pdf

User question: Tell me a fun fact about Llama.
Your answer:
A baby llama is called "Cria" [citation:xyz]().
It often live in desert [citation:abc]().
It\'s cute animal.
'

NEXT_PUBLIC_AUTH_BACKEND=

#Okta FGA Configurations
FGA_API_URL=

FGA_API_AUDIENCE=

FGA_API_TOKEN_ISSUER=

FGA_STORE_ID=

FGA_MODEL_ID=

FGA_CLIENT_ID=

FGA_CLIENT_SECRET=

#Paragon specific configurations
NEXT_PUBLIC_PARAGON_PROJECT_ID=

SIGNING_KEY=

SEND_SLACK_ENDPOINT=

CREATE_SALESFORCE_CONTACT_ENDPOINT=